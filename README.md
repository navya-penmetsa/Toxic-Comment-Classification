TOXIC COMMENT CLASSIFICATION
   
Source: https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification
   
Description: https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/overview/description
   
OVERVIEW

This project focuses on building a multi-label classification model to identify and categorize toxic comments from online platforms. Using advanced NLP and deep learning techniques, the model detects types of toxicity such as insult, threat, obscene, and identity hate.


KEY FEATURES

Multi-label classification using Keras and TensorFlow

Applied CNN and Bi-GRU architectures

Utilized GloVe word embeddings for semantic representation

Preprocessed data with text cleaning, tokenization, and padding

Evaluated performance with ROC-AUC, learning curves, and confusion matrices


TECH STACK

Python, TensorFlow, Keras

NLP (GloVe, Tokenizer, Pad Sequences)

Model Evaluation (ROC, Accuracy, Confusion Matrix)


RESULTS

CNN Accuracy: 97.45%

bi-GRU Accuracy: 93.76%

